{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for the complete network, dataset creation, and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import torchio as tio\n",
    "from torch.utils.data import dataloader\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchtuples as tt\n",
    "from pycox.models import LogisticHazard\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "np.random.seed(1234)\n",
    "_ = torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anders/.local/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load data into dataframes \n",
    "\n",
    "metadata =pd.read_csv(\"/home/anders/Phd_Interview_project_dataset/metadata.csv\")\n",
    "pat_ct = metadata.loc[(metadata['Modality'] == \"CT\")]\n",
    "patients = pat_ct[\"Subject ID\"].to_numpy()\n",
    "pat_ct.set_index('Subject ID', inplace=True)\n",
    "\n",
    "data = pd.read_excel(\"Colorectal-Liver-Metastases-Clinical-data-April-2023.xlsx\")\n",
    "surv_data = data[[\"Patient-ID\", \"vital_status\", \"overall_survival_months\"]].copy()\n",
    "data.drop(columns=[\"vital_status\", \"overall_survival_months\", \"De-identify Scout Name\", \"months_to_DFS_progression\", \"vital_status_DFS\", \"months_to_liver_DFS_progression\", \"vital_status_liver_DFS\", \"relevant_notes\", \"progression_or_recurrence\", \"progression_or_recurrence_liveronly\"], inplace=True)\n",
    "\n",
    "\n",
    "# Helper functions \n",
    "\n",
    "def Get_pat_imgs(df, patientid):\n",
    "    loc = \"/home/anders/Phd_Interview_project_dataset/\" + df.loc[patientid][\"File Location\"][2:] + \"/\"\n",
    "    return loc\n",
    "\n",
    "def get_pat_surv_dat(df, patientid):\n",
    "    data = torch.asarray(df.loc[df[\"Patient-ID\"] == patientid].iloc[:,1:].values[0])\n",
    "    return data[0], data[1]\n",
    "\n",
    "def Get_patient_covariate_data(df, patient_ID):\n",
    "    return torch.asarray(df.loc[df[\"Patient-ID\"] == patient_ID].iloc[:,1:].values[0]).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition into train and val set\n",
    "train_data = data\n",
    "test_data = data.sample(frac=0.2)\n",
    "train_data = train_data.drop(test_data.index)\n",
    "\n",
    "surv_train_targ = surv_data.drop(test_data[\"Patient-ID\"].index)\n",
    "surv_test_targ = surv_data.drop(train_data[\"Patient-ID\"].index)\n",
    "\n",
    "#Perform label transform and discretization of the datapoints\n",
    "labtrans = LogisticHazard.label_transform(20)\n",
    "target_train = labtrans.fit_transform(surv_train_targ[\"overall_survival_months\"].values, surv_train_targ[\"vital_status\"].values)\n",
    "target_test = labtrans.fit_transform(surv_test_targ[\"overall_survival_months\"].values, surv_test_targ[\"vital_status\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a torchio dataset that is also compatible with the Pycox environment\n",
    "# Dataloader needs to output this:  input, target = data\n",
    "\n",
    "class FusionSurvDataset():\n",
    "    def __init__(self, tiodataset, time, event):\n",
    "        self.tiodataset = tiodataset\n",
    "        self.time, self.event = tt.tuplefy(time, event).to_tensor()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.time)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        data = self.tiodataset[indx]\n",
    "        img = data.image.data\n",
    "        covariates = data.covariates\n",
    "        return tt.tuplefy((img, covariates), (self.time[indx], self.event[indx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16,  4, 13, 13,  3, 14,  4, 10, 12, 15, 12, 13, 11, 18, 16, 16,  4,\n",
       "         5, 17, 12,  3,  9, 10,  8, 11, 11, 13,  3, 11,  5, 13, 10,  5,  7,\n",
       "        13,  3,  5,  1, 13,  3, 10, 14,  2,  7,  6, 15, 15,  4,  6, 13, 12,\n",
       "         9, 17, 10,  9, 17, 11,  5,  8,  2, 14, 15,  5, 14,  5, 10, 17, 13,\n",
       "         1,  8, 17,  4, 10, 11, 12, 17,  6, 18, 14,  6,  5,  8,  3,  9,  5,\n",
       "         5, 10, 18, 15, 11, 16, 13,  4,  5, 14,  8,  5,  6, 13,  7, 13, 14,\n",
       "        12, 15, 14,  3,  2, 11,  9,  3,  8,  8,  8,  5, 16,  7, 11, 17,  8,\n",
       "         7,  3,  7,  5,  8,  9, 16,  9,  7,  8, 15, 19, 12, 13,  8,  8, 13,\n",
       "         2, 10, 10,  3, 14,  9,  6,  4,  5, 17,  9,  3, 17,  4, 15,  6,  2,\n",
       "        12,  4, 14, 15, 15]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transforms = tio.Compose([\n",
    "    tio.Resample(1),\n",
    "    tio.ZNormalization(),\n",
    "    tio.Resize((128,128,240))\n",
    "])\n",
    "\n",
    "def Get_Subjects(Idlist):\n",
    "    Subject_list = []\n",
    "    for i,subject in enumerate(Idlist):\n",
    "        dir = Get_pat_imgs(pat_ct, subject)\n",
    "        covariates = Get_patient_covariate_data(data, subject)\n",
    "        event, time = get_pat_surv_dat(surv_data, subject)\n",
    "        subject = tio.Subject(\n",
    "        image = tio.ScalarImage(dir),\n",
    "        covariates = covariates,\n",
    "        )\n",
    "        Subject_list.append(subject)\n",
    "    return Subject_list\n",
    "\n",
    "#Training split\n",
    "Train_Subjects = Get_Subjects(surv_train_targ[\"Patient-ID\"].to_list())\n",
    "Train_tio_dataset = tio.SubjectsDataset(Train_Subjects, transform=Transforms)\n",
    "Train_Fusion_dataset = FusionSurvDataset(Train_tio_dataset, target_train[0], target_train[1])\n",
    "\n",
    "#Validation / Testing split \n",
    "Test_Subjects = Get_Subjects(surv_test_targ[\"Patient-ID\"].to_list())\n",
    "Test_tio_dataset = tio.SubjectsDataset(Test_Subjects, transform=Transforms)\n",
    "Test_Fusion_dataset = FusionSurvDataset(Test_tio_dataset, target_test[0], target_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need the Pycox-collate \n",
    "def collate_fn(batch):\n",
    "    \"\"\"Stacks the entries of a nested tuple\"\"\"\n",
    "    return tt.tuplefy(batch).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(Train_Fusion_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "dl_test = DataLoader(Test_Fusion_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dl_train))\n",
    "covdata = batch[0][1]\n",
    "covdata.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the network\n",
    "class FusionSurv(nn.Module):\n",
    "    \n",
    "    def __init__(self, clinical_inputs=25, ct_cov=12, clin_cov=12, out_haz=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.CT_net = nn.Sequential(\n",
    "            # \n",
    "            nn.Conv3d(1, 2, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(2),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv3d(2, 4, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(4),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv3d(4, 8, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv3d(8, 1, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(1), \n",
    "            nn.Flatten(start_dim=2),\n",
    "            nn.Linear(960, ct_cov),\n",
    "            nn.ReLU(), # some of the outputs are 0, but this should be fine?\n",
    "            #nn.Sigmoid(), # create logits # I shouldn't need to apply sigmoid yet, and risk saturating the gradients.\n",
    "        )\n",
    "\n",
    "        self.Clin_net = nn.Sequential(\n",
    "            nn.Linear(clinical_inputs, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(16, clin_cov),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.Surv_net = nn.Sequential(\n",
    "            nn.Linear(ct_cov + clin_cov, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(32, out_haz),\n",
    "            nn.Sigmoid(), # Sigmoid to create logistic hazard outputs.\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, im, clin):\n",
    "        imcov   = self.CT_net(im)\n",
    "        clincov = self.Clin_net(clin.unsqueeze(dim=1))\n",
    "        return self.Surv_net(torch.cat((imcov, clincov), axis=2)).squeeze(1)\n",
    "    \n",
    "    def predict(self, im, clin):\n",
    "        # Pycox uses predict for the survival functions, but since this is a fusion net there really isn't a part of the network that should work independently.\n",
    "        return self.forward(im, clin)\n",
    "\n",
    "# takes input [Batch,1,240,128,128], and [Batch,1,25] --> returns [batch,1,haz_out] where hazard out are the hazards for each discrete step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FusionSurv(out_haz=labtrans.out_features)\n",
    "\n",
    "model = LogisticHazard(net, tt.optim.Adam(0.01), duration_index=labtrans.cuts, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[3m:30s / 3m:30s],\t\ttrain_loss: 7.8100,\tval_loss: 7.3634\n"
     ]
    }
   ],
   "source": [
    "callbacks = [tt.cb.EarlyStopping(patience=5)]\n",
    "epochs = 5\n",
    "verbose = True\n",
    "log = model.fit_dataloader(dl_train, epochs, callbacks, verbose, val_dataloader=dl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
