{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for the complete network, dataset creation, and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anders/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import torchio as tio\n",
    "from torch.utils.data import dataloader\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchtuples as tt\n",
    "from pycox.models import LogisticHazard\n",
    "from pycox.evaluation import EvalSurv\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1234)\n",
    "_ = torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anders/.local/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load data into dataframes \n",
    "\n",
    "metadata =pd.read_csv(\"/home/anders/Phd_Interview_project_dataset/metadata.csv\")\n",
    "pat_ct = metadata.loc[(metadata['Modality'] == \"CT\")]\n",
    "patients = pat_ct[\"Subject ID\"].to_numpy()\n",
    "pat_ct.set_index('Subject ID', inplace=True)\n",
    "\n",
    "data = pd.read_excel(\"Colorectal-Liver-Metastases-Clinical-data-April-2023.xlsx\")\n",
    "surv_data = data[[\"Patient-ID\", \"vital_status\", \"overall_survival_months\"]].copy()\n",
    "data.drop(columns=[\"vital_status\", \"overall_survival_months\", \"De-identify Scout Name\", \"months_to_DFS_progression\", \"vital_status_DFS\", \"months_to_liver_DFS_progression\", \"vital_status_liver_DFS\", \"relevant_notes\", \"progression_or_recurrence\", \"progression_or_recurrence_liveronly\"], inplace=True)\n",
    "\n",
    "\n",
    "# Helper functions \n",
    "\n",
    "def Get_pat_imgs(df, patientid):\n",
    "    loc = \"/home/anders/Phd_Interview_project_dataset/\" + df.loc[patientid][\"File Location\"][2:] + \"/\"\n",
    "    return loc\n",
    "\n",
    "def get_pat_surv_dat(df, patientid):\n",
    "    data = torch.asarray(df.loc[df[\"Patient-ID\"] == patientid].iloc[:,1:].values[0])\n",
    "    return data[0], data[1]\n",
    "\n",
    "def Get_patient_covariate_data(df, patient_ID):\n",
    "    return torch.asarray(df.loc[df[\"Patient-ID\"] == patient_ID].iloc[:,1:].values[0]).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition into train and val set\n",
    "train_data = data\n",
    "test_data = data.sample(frac=0.2)\n",
    "train_data = train_data.drop(test_data.index)\n",
    "\n",
    "surv_train_targ = surv_data.drop(test_data[\"Patient-ID\"].index)\n",
    "surv_test_targ = surv_data.drop(train_data[\"Patient-ID\"].index)\n",
    "\n",
    "#Perform label transform and discretization of the datapoints\n",
    "labtrans = LogisticHazard.label_transform(20)\n",
    "target_train = labtrans.fit_transform(surv_train_targ[\"overall_survival_months\"].values, surv_train_targ[\"vital_status\"].values)\n",
    "target_test = labtrans.fit_transform(surv_test_targ[\"overall_survival_months\"].values, surv_test_targ[\"vital_status\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a torchio dataset that is also compatible with the Pycox environment\n",
    "# Dataloader needs to output this:  input, target = data\n",
    "\n",
    "class FusionSurvDataset():\n",
    "    def __init__(self, tiodataset, time, event, testmode=False):\n",
    "        self.tiodataset = tiodataset\n",
    "        self.time, self.event = tt.tuplefy(time, event).to_tensor()\n",
    "        self.testmode = testmode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.time)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        data = self.tiodataset[indx]\n",
    "        img = data.image.data\n",
    "        covariates = data.covariates\n",
    "        if not self.testmode:\n",
    "            return tt.tuplefy((img, covariates), (self.time[indx], self.event[indx]))\n",
    "        else:\n",
    "            return tt.tuplefy((img, covariates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16,  4, 13, 13,  3, 14,  4, 10, 12, 15, 12, 13, 11, 18, 16, 16,  4,\n",
       "         5, 17, 12,  3,  9, 10,  8, 11, 11, 13,  3, 11,  5, 13, 10,  5,  7,\n",
       "        13,  3,  5,  1, 13,  3, 10, 14,  2,  7,  6, 15, 15,  4,  6, 13, 12,\n",
       "         9, 17, 10,  9, 17, 11,  5,  8,  2, 14, 15,  5, 14,  5, 10, 17, 13,\n",
       "         1,  8, 17,  4, 10, 11, 12, 17,  6, 18, 14,  6,  5,  8,  3,  9,  5,\n",
       "         5, 10, 18, 15, 11, 16, 13,  4,  5, 14,  8,  5,  6, 13,  7, 13, 14,\n",
       "        12, 15, 14,  3,  2, 11,  9,  3,  8,  8,  8,  5, 16,  7, 11, 17,  8,\n",
       "         7,  3,  7,  5,  8,  9, 16,  9,  7,  8, 15, 19, 12, 13,  8,  8, 13,\n",
       "         2, 10, 10,  3, 14,  9,  6,  4,  5, 17,  9,  3, 17,  4, 15,  6,  2,\n",
       "        12,  4, 14, 15, 15]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transforms = tio.Compose([\n",
    "    tio.Resample(1),\n",
    "    tio.ZNormalization(),\n",
    "    tio.Resize((128,128,240))\n",
    "])\n",
    "\n",
    "def Get_Subjects(Idlist):\n",
    "    Subject_list = []\n",
    "    for i,subject in enumerate(Idlist):\n",
    "        dir = Get_pat_imgs(pat_ct, subject)\n",
    "        covariates = Get_patient_covariate_data(data, subject)\n",
    "        event, time = get_pat_surv_dat(surv_data, subject)\n",
    "        subject = tio.Subject(\n",
    "        image = tio.ScalarImage(dir),\n",
    "        covariates = covariates,\n",
    "        )\n",
    "        Subject_list.append(subject)\n",
    "    return Subject_list\n",
    "\n",
    "Train_Subjects = Get_Subjects(surv_train_targ[\"Patient-ID\"].to_list())\n",
    "Test_Subjects = Get_Subjects(surv_test_targ[\"Patient-ID\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all subjects into ram for faster iterations\n",
    "\n",
    "def LoadSubjectList(Subjectlist):\n",
    "    print('Loading data from', Subjectlist,'...')\n",
    "    for subject in tqdm(Subjectlist):\n",
    "        subject.load()  # load images, caching the voxel data in RAM\n",
    "#This didn't actually help\n",
    "#LoadSubjectList(Train_Subjects)\n",
    "#LoadSubjectList(Test_Subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training split\n",
    "Train_tio_dataset = tio.SubjectsDataset(Train_Subjects, transform=Transforms)\n",
    "Train_Fusion_dataset = FusionSurvDataset(Train_tio_dataset, target_train[0], target_train[1])\n",
    "\n",
    "#Validation / Testing split \n",
    "Test_tio_dataset = tio.SubjectsDataset(Test_Subjects, transform=Transforms)\n",
    "Test_Fusion_dataset = FusionSurvDataset(Test_tio_dataset, target_test[0], target_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need the Pycox-collate \n",
    "def collate_fn(batch):\n",
    "    \"\"\"Stacks the entries of a nested tuple\"\"\"\n",
    "    return tt.tuplefy(batch).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(Train_Fusion_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "dl_test = DataLoader(Test_Fusion_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dl_train))\n",
    "covdata = batch[0][1]\n",
    "covdata.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the network\n",
    "class FusionSurv(nn.Module):\n",
    "    \n",
    "    def __init__(self, clinical_inputs=25, ct_cov=12, clin_cov=12, out_haz=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.CT_net = nn.Sequential(\n",
    "            # \n",
    "            nn.Conv3d(1, 2, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(2),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv3d(2, 4, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(4),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv3d(4, 8, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv3d(8, 1, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(1), \n",
    "            nn.Flatten(start_dim=2),\n",
    "            nn.Linear(960, ct_cov),\n",
    "            nn.ReLU(), # some of the outputs are 0, but this should be fine?\n",
    "            #nn.Sigmoid(), # create logits # I shouldn't need to apply sigmoid yet, and risk saturating the gradients.\n",
    "        )\n",
    "\n",
    "        self.Clin_net = nn.Sequential(\n",
    "            nn.Linear(clinical_inputs, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(16, clin_cov),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.Surv_net = nn.Sequential(\n",
    "            nn.Linear(ct_cov + clin_cov, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(32, out_haz),\n",
    "            nn.Sigmoid(), # Sigmoid to create logistic hazard outputs.\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, *args):\n",
    "        try:\n",
    "            im, clin = args[0], args[1]\n",
    "        except:\n",
    "            im, clin = args[0][0], args[0][1]\n",
    "\n",
    "        imcov   = self.CT_net(im)\n",
    "        clincov = self.Clin_net(clin.unsqueeze(dim=1))\n",
    "        return self.Surv_net(torch.cat((imcov, clincov), axis=2)).squeeze(1)\n",
    "    \n",
    "    def predict(self, im, clin):\n",
    "        # Pycox uses predict for the survival functions, but since this is a fusion net there really isn't a part of the network that should work independently.\n",
    "        return self.forward(im, clin)\n",
    "    \n",
    "# takes input [Batch,1,240,128,128], and [Batch,1,25] --> returns [batch,1,haz_out] where hazard out are the hazards for each discrete step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FusionSurv(out_haz=labtrans.out_features)\n",
    "\n",
    "model = LogisticHazard(net, tt.optim.Adam(0.01), duration_index=labtrans.cuts, device=\"cuda\")\n",
    "#model.load_model_weights(\"myweights_prime.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anders/.local/lib/python3.10/site-packages/torchio/transforms/transform.py:165: RuntimeWarning: Output shape (128, 128, 241) != target shape (128, 128, 240). Fixing with CropOrPad\n",
      "  transformed = self.apply_transform(subject)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[3m:45s / 3m:45s],\t\ttrain_loss: 7.7363,\tval_loss: 7.3574\n",
      "1:\t[3m:48s / 7m:34s],\t\ttrain_loss: 7.3860,\tval_loss: 7.3561\n",
      "2:\t[3m:49s / 11m:23s],\t\ttrain_loss: 7.3930,\tval_loss: 7.3552\n",
      "3:\t[3m:49s / 15m:13s],\t\ttrain_loss: 7.3447,\tval_loss: 7.3547\n",
      "4:\t[3m:51s / 19m:5s],\t\ttrain_loss: 7.3746,\tval_loss: 7.3543\n",
      "5:\t[3m:50s / 22m:55s],\t\ttrain_loss: 7.3527,\tval_loss: 7.3541\n",
      "6:\t[3m:49s / 26m:45s],\t\ttrain_loss: 7.4001,\tval_loss: 7.3539\n",
      "7:\t[3m:41s / 30m:26s],\t\ttrain_loss: 7.3567,\tval_loss: 7.3537\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m      3\u001b[0m verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmyweights.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchtuples/base.py:231\u001b[0m, in \u001b[0;36mModel.fit_dataloader\u001b[0;34m(self, dataloader, epochs, callbacks, verbose, metrics, val_dataloader)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    232\u001b[0m     stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_batch_start()\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mFusionSurvDataset.__getitem__\u001b[0;34m(self, indx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indx):\n\u001b[0;32m---> 14\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtiodataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     16\u001b[0m     covariates \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcovariates\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/data/dataset.py:99\u001b[0m, in \u001b[0;36mSubjectsDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Apply transform (this is usually the bottleneck)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     subject \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subject\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/transform.py:165\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    163\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 165\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/augmentation/composition.py:51\u001b[0m, in \u001b[0;36mCompose.apply_transform\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, subject: Subject) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Subject:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 51\u001b[0m         subject \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m subject\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/transform.py:165\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    163\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 165\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/preprocessing/spatial/resize.py:65\u001b[0m, in \u001b[0;36mResize.apply_transform\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m     59\u001b[0m spacing_out \u001b[38;5;241m=\u001b[39m shape_in \u001b[38;5;241m/\u001b[39m shape_out \u001b[38;5;241m*\u001b[39m spacing_in\n\u001b[1;32m     60\u001b[0m resample \u001b[38;5;241m=\u001b[39m Resample(\n\u001b[1;32m     61\u001b[0m     spacing_out,\n\u001b[1;32m     62\u001b[0m     image_interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_interpolation,\n\u001b[1;32m     63\u001b[0m     label_interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_interpolation,\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m resampled \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resampled, Subject)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Sometimes, the output shape is one voxel too large\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Probably because Resample uses np.ceil to compute the shape\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/transform.py:165\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    163\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 165\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/preprocessing/spatial/resample.py:189\u001b[0m, in \u001b[0;36mResample.apply_transform\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m    186\u001b[0m         matrix \u001b[38;5;241m=\u001b[39m matrix\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    187\u001b[0m     image\u001b[38;5;241m.\u001b[39maffine \u001b[38;5;241m=\u001b[39m matrix \u001b[38;5;241m@\u001b[39m image\u001b[38;5;241m.\u001b[39maffine\n\u001b[0;32m--> 189\u001b[0m floating_sitk \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_sitk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce_3d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m resampler \u001b[38;5;241m=\u001b[39m sitk\u001b[38;5;241m.\u001b[39mResampleImageFilter()\n\u001b[1;32m    192\u001b[0m resampler\u001b[38;5;241m.\u001b[39mSetInterpolator(interpolator)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/data/image.py:638\u001b[0m, in \u001b[0;36mImage.as_sitk\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_sitk\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m sitk\u001b[38;5;241m.\u001b[39mImage:\n\u001b[1;32m    637\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the image as an instance of :class:`sitk.Image`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnib_to_sitk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/data/io.py:314\u001b[0m, in \u001b[0;36mnib_to_sitk\u001b[0;34m(data, affine, force_3d, force_4d)\u001b[0m\n\u001b[1;32m    312\u001b[0m     array \u001b[38;5;241m=\u001b[39m array[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    313\u001b[0m array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mtranspose()  \u001b[38;5;66;03m# (W, H, D, C) or (W, H, D)\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43msitk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetImageFromArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misVector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_multichannel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m origin, spacing, direction \u001b[38;5;241m=\u001b[39m get_sitk_metadata_from_ras_affine(\n\u001b[1;32m    317\u001b[0m     affine,\n\u001b[1;32m    318\u001b[0m     is_2d\u001b[38;5;241m=\u001b[39mis_2d,\n\u001b[1;32m    319\u001b[0m )\n\u001b[1;32m    320\u001b[0m image\u001b[38;5;241m.\u001b[39mSetOrigin(origin)  \u001b[38;5;66;03m# should I add a 4th value if force_4d?\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/SimpleITK/extra.py:326\u001b[0m, in \u001b[0;36mGetImageFromArray\u001b[0;34m(arr, isVector)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# SimpleITK throws an exception if the image dimension is not supported\u001b[39;00m\n\u001b[1;32m    324\u001b[0m img \u001b[38;5;241m=\u001b[39m Image(shape, \u001b[38;5;28mid\u001b[39m, number_of_components)\n\u001b[0;32m--> 326\u001b[0m \u001b[43m_SetImageFromArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [tt.cb.EarlyStopping(patience=5)]\n",
    "epochs = 15\n",
    "verbose = True\n",
    "log = model.fit_dataloader(dl_train, epochs, callbacks, verbose, val_dataloader=dl_test)\n",
    "model.save_model_weights('myweights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m Sim_Test_Fusion_dataset \u001b[38;5;241m=\u001b[39m FusionSurvDataset(Test_tio_dataset, target_test[\u001b[38;5;241m0\u001b[39m], target_test[\u001b[38;5;241m1\u001b[39m], testmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m Sim_Test_Fusion_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(Sim_Test_Fusion_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[0;32m----> 3\u001b[0m surv \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_surv_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSim_Test_Fusion_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m ev \u001b[38;5;241m=\u001b[39m EvalSurv(surv, target_test[\u001b[38;5;241m0\u001b[39m], target_test[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycox/models/interpolation.py:113\u001b[0m, in \u001b[0;36mInterpolateDiscrete.predict_surv_df\u001b[0;34m(self, input, batch_size, eval_, to_cpu, num_workers)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_surv_df\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8224\u001b[39m, eval_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, to_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict the survival function for `input` and return as a pandas DataFrame.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    See `predict_surv` to return tensor or np.array instead.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m        pd.DataFrame -- Predictions\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     surv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_surv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycox/models/interpolation.py:150\u001b[0m, in \u001b[0;36mInterpolateLogisticHazard.predict_surv\u001b[0;34m(self, input, batch_size, numpy, eval_, to_cpu, num_workers)\u001b[0m\n\u001b[1;32m    148\u001b[0m     surv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_surv_const_haz(\u001b[38;5;28minput\u001b[39m, batch_size, numpy, eval_, to_cpu, num_workers)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst_pdf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlin_surv\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 150\u001b[0m     surv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_surv_const_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycox/models/interpolation.py:87\u001b[0m, in \u001b[0;36mInterpolateDiscrete._surv_const_pdf\u001b[0;34m(self, input, batch_size, numpy, eval_, to_cpu, num_workers)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_surv_const_pdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8224\u001b[39m, numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, to_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     69\u001b[0m                     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Basic method for constant PDF interpolation that use `self.model.predict_surv`.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m        [np.ndarray or tensor] -- Predictions\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_surv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     n, m \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     89\u001b[0m     device \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycox/models/logistic_hazard.py:76\u001b[0m, in \u001b[0;36mLogisticHazard.predict_surv\u001b[0;34m(self, input, batch_size, numpy, eval_, to_cpu, num_workers, epsilon)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_surv\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8224\u001b[39m, numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, to_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m                  num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m):\n\u001b[0;32m---> 76\u001b[0m     hazard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_hazard\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     surv \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m hazard)\u001b[38;5;241m.\u001b[39madd(epsilon)\u001b[38;5;241m.\u001b[39mlog()\u001b[38;5;241m.\u001b[39mcumsum(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexp()\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tt\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39marray_or_tensor(surv, numpy, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycox/models/logistic_hazard.py:83\u001b[0m, in \u001b[0;36mLogisticHazard.predict_hazard\u001b[0;34m(self, input, batch_size, numpy, eval_, to_cpu, num_workers)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_hazard\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8224\u001b[39m, numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, to_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m                    num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 83\u001b[0m     hazard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msigmoid()\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tt\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39marray_or_tensor(hazard, numpy, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchtuples/base.py:639\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, input, batch_size, numpy, eval_, grads, to_cpu, num_workers, is_dataloader, func, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_net(\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    627\u001b[0m         batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    636\u001b[0m     )\n\u001b[1;32m    638\u001b[0m pred_func \u001b[38;5;241m=\u001b[39m wrapfunc(func, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mpredict)\n\u001b[0;32m--> 639\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_or_tensor(preds, numpy, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchtuples/base.py:536\u001b[0m, in \u001b[0;36mModel._predict_func\u001b[0;34m(self, func, input, batch_size, numpy, eval_, grads, to_cpu, num_workers, is_dataloader, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not recognize data type. You can set `is_dataloader to `True`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or `False` to force usage.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    535\u001b[0m to_cpu \u001b[38;5;241m=\u001b[39m numpy \u001b[38;5;129;01mor\u001b[39;00m to_cpu\n\u001b[0;32m--> 536\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_func_dl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_or_tensor(preds, numpy, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchtuples/base.py:491\u001b[0m, in \u001b[0;36mModel._predict_func_dl\u001b[0;34m(self, func, dataloader, numpy, eval_, grads, to_cpu)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(grads):\n\u001b[1;32m    490\u001b[0m     preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m tuplefy(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39mto_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    493\u001b[0m         preds_batch \u001b[38;5;241m=\u001b[39m tuplefy(func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mFusionSurvDataset.__getitem__\u001b[0;34m(self, indx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indx):\n\u001b[0;32m---> 14\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtiodataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     16\u001b[0m     covariates \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcovariates\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/data/dataset.py:99\u001b[0m, in \u001b[0;36mSubjectsDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Apply transform (this is usually the bottleneck)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     subject \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subject\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/transform.py:165\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    163\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 165\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/augmentation/composition.py:51\u001b[0m, in \u001b[0;36mCompose.apply_transform\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, subject: Subject) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Subject:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 51\u001b[0m         subject \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m subject\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/transform.py:165\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    163\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 165\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/preprocessing/intensity/normalization_transform.py:50\u001b[0m, in \u001b[0;36mNormalizationTransform.apply_transform\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_name, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_images_dict(subject)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     45\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mask_from_masking_method(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking_method,\n\u001b[1;32m     47\u001b[0m         subject,\n\u001b[1;32m     48\u001b[0m         image\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_normalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subject\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/preprocessing/intensity/z_normalization.py:31\u001b[0m, in \u001b[0;36mZNormalization.apply_normalization\u001b[0;34m(self, subject, image_name, mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_normalization\u001b[39m(\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     26\u001b[0m     subject: Subject,\n\u001b[1;32m     27\u001b[0m     image_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     28\u001b[0m     mask: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m     29\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     image \u001b[38;5;241m=\u001b[39m subject[image_name]\n\u001b[0;32m---> 31\u001b[0m     standardized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mznorm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m standardized \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandard deviation is 0 for masked values\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in image \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchio/transforms/preprocessing/intensity/z_normalization.py:50\u001b[0m, in \u001b[0;36mZNormalization.znorm\u001b[0;34m(tensor, mask)\u001b[0m\n\u001b[1;32m     48\u001b[0m tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     49\u001b[0m values \u001b[38;5;241m=\u001b[39m tensor[mask]\n\u001b[0;32m---> 50\u001b[0m mean, std \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, values\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Sim_Test_Fusion_dataset = FusionSurvDataset(Test_tio_dataset, target_test[0], target_test[1], testmode=True)\n",
    "Sim_Test_Fusion_dataloader = DataLoader(Sim_Test_Fusion_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "surv = model.interpolate(10).predict_surv_df(Sim_Test_Fusion_dataloader)\n",
    "ev = EvalSurv(surv, target_test[0], target_test[1], 'km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4858757062146893"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.concordance_td()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3351162764937678"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_grid = np.linspace(0, target_test[0].max())\n",
    "ev.brier_score(time_grid).plot()\n",
    "plt.ylabel('Brier score')\n",
    "_ = plt.xlabel('Time')\n",
    "ev.integrated_brier_score(time_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anders/.local/lib/python3.10/site-packages/torchio/transforms/transform.py:165: RuntimeWarning: Output shape (128, 128, 241) != target shape (128, 128, 240). Fixing with CropOrPad\n",
      "  transformed = self.apply_transform(subject)\n"
     ]
    }
   ],
   "source": [
    "# Moving on to the Shap portion. First attempt will be with the SHAP-package. \n",
    "batch = next(iter(Sim_Test_Fusion_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_tuple = [batch[0][:12,:,:,:,:], batch[1][:12,:]]\n",
    "test_tuple = [batch[0][12:16,:,:,:,:], batch[1][12:16,:]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Run once to calcualte SHAP\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer(test_tuple)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_deep/__init__.py:86\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m TFDeep(model, data, session, learning_phase_flags)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mPyTorchDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mexpected_value\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m=\u001b[39m framework\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_deep/deep_pytorch.py:53\u001b[0m, in \u001b[0;36mPyTorchDeep.__init__\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 53\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# also get the device everything is running on\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[12], line 61\u001b[0m, in \u001b[0;36mFusionSurv.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     im, clin \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 61\u001b[0m imcov   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCT_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m clincov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mClin_net(clin\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSurv_net(torch\u001b[38;5;241m.\u001b[39mcat((imcov, clincov), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "#Run once to calcualte SHAP\n",
    "explainer = shap.DeepExplainer(net, background_tuple)\n",
    "\n",
    "shap_values = explainer(test_tuple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 25, 20)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The waterfall plot requires an `Explanation` object as the `shap_values` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Have fun with SHAP here:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#shap.summary_plot(shap_values[1], test_tuple, plot_type=\"waterfall\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaterfall_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/plots/_waterfall.py:56\u001b[0m, in \u001b[0;36mwaterfall\u001b[0;34m(shap_values, max_display, show)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shap_values, Explanation):\n\u001b[1;32m     52\u001b[0m     emsg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe waterfall plot requires an `Explanation` object as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shap_values` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m     )\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(emsg)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# make sure we only have a single explanation to plot\u001b[39;00m\n\u001b[1;32m     59\u001b[0m sv_shape \u001b[38;5;241m=\u001b[39m shap_values\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: The waterfall plot requires an `Explanation` object as the `shap_values` argument."
     ]
    }
   ],
   "source": [
    "#Have fun with SHAP here:\n",
    "#shap.summary_plot(shap_values[1], test_tuple, plot_type=\"waterfall\")\n",
    "\n",
    "shap.waterfall_plot(shap_values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
