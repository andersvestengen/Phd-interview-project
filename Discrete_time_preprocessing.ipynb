{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals  \n",
    "    1. Load the clinical variables\n",
    "    2. Process the data as a pandas dataframe\n",
    "    3. Research SurvhShap, speficially what kind of data it expects.\n",
    "    4. Create m parameter-cuts of the data as equidistant\n",
    "    5. Implement an event-sorting algorithm based on the cuts and events.\n",
    "    6. Finish processing the data so its ready for training\n",
    "    7. Setup a network alongside the binary-cross-loss (sigmoid on the network output).\n",
    "    8. Implement a function to create survival function for the chosen slices (0, m)\n",
    "    9. Plot survival for five individuals\n",
    "    10. plot accuracy\n",
    "    11. attempt C-index or Brier score on the network outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anders/.local/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#1. Load the clinical data\n",
    "data = pd.read_excel(\"Colorectal-Liver-Metastases-Clinical-data-April-2023.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_set = data\\nval_set = train_set.sample(frac=0.2)\\ntrain_set.drop(val_set.index, inplace=True)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Process the data as pandas dataframe\n",
    "#Dropping the DFS as I'm going to be modeling ordinary survival, without competing interests\n",
    "surv_data = data[[\"vital_status\", \"overall_survival_months\"]].copy()\n",
    "identity_data = data[[\"Patient-ID\", \"De-identify Scout Name\"]].copy()\n",
    "data.drop(columns=[\"vital_status\", \"overall_survival_months\", \"Patient-ID\", \"De-identify Scout Name\", \"months_to_DFS_progression\", \"vital_status_DFS\", \"months_to_liver_DFS_progression\", \"vital_status_liver_DFS\", \"relevant_notes\", \"progression_or_recurrence\", \"progression_or_recurrence_liveronly\"], inplace=True)\n",
    "\n",
    "\"\"\"\n",
    "train_set = data\n",
    "val_set = train_set.sample(frac=0.2)\n",
    "train_set.drop(val_set.index, inplace=True)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.util import Surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 2)\n",
      "(158,) (39,)\n",
      "(158, 25) (39, 25)\n"
     ]
    }
   ],
   "source": [
    "#Do not run this cell more than once!\n",
    "#Creating Train and validation sets (using validation as test and validation. )\n",
    "X_train = data\n",
    "X_val = X_train.sample(frac=0.2)\n",
    "X_train.drop(X_val.index, inplace=True)\n",
    "surv_data_train = surv_data.drop(X_val.index)\n",
    "surv_data_val = surv_data.drop(X_train.index)\n",
    "Y_train = Surv.from_dataframe(\"vital_status\", \"overall_survival_months\", surv_data_train)\n",
    "Y_val   = Surv.from_dataframe(\"vital_status\", \"overall_survival_months\", surv_data_val)\n",
    "print(surv_data.shape)\n",
    "print(Y_train.shape, Y_val.shape)\n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Research what types of the data the SurvShap package expects as input\n",
    "\n",
    "In the original tutorial notebook the data for training and validation go through the same process as the cell above, where the X_train containing the covariates are pandas dataframes and the Y_train have gone through the Surv() package. \n",
    "\n",
    "SurvShap also expects some function that returns the Survival equation for all the time-steps based on the network output, and this has to come on the form: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So models like the LogisticHazard use sigmoid on the output to essentially output hazard functions for each of the [0,m] times, and then uses binary cross entropy loss to train the network, but what does it train against? No dataset contains h or S values for comparison, so how do you steer this thing?  \n",
    "\n",
    "The answer is that it assumes the ideal network output is 1 or 0 for the appropriate event_duration.  \n",
    "\n",
    "so the network could output: 0,0,0,0,1,0,0,1  \n",
    "which could be compared to:  0,0,1,0,0,0,0,1\n",
    "\n",
    "using the BCE with logits loss.\n",
    "\n",
    "In fact I could probably import the loss and the surv and hazard functions from the class to do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
